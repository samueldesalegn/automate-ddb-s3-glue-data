AWSTemplateFormatVersion: '2010-09-09'
Transform: 'AWS::Serverless-2016-10-31'

Resources:

  # S3 Bucket where the Parquet files will be stored
  S3BucketForParquet:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: 'aws-customer-survey-analytics'

  # Glue Workflow to manage job execution
  GlueWorkflow:
    Type: 'AWS::Glue::Workflow'
    Properties:
      Name: 'DynamoDBtoS3Workflow'

  # Glue Job resource to extract data from DynamoDB and store in S3 (PythonShell with Python 3.9)
  GlueDynamoDBtoS3Job:
    Type: 'AWS::Glue::Job'
    Properties:
      Role: !Sub 'arn:aws:iam::${AWS::AccountId}:role/glue-processor-role'
      Command:
        Name: 'pythonshell'
        ScriptLocation: glue-scripts/dynamodb-to-parquet.py
        PythonVersion: '3.9'  # Set Python version to 3.9
      MaxCapacity: 0.0625
      DefaultArguments:
        '--TempDir': 's3://aws-customer-survey-analytics/glue-temp/'
        '--job-language': 'python'
        '--enable-continuous-cloudwatch-log': 'true'
    DependsOn: S3BucketForParquet

  # Glue Trigger to automatically start the job within the Workflow on a schedule
  GlueTrigger:
    Type: 'AWS::Glue::Trigger'
    Properties:
      Type: 'SCHEDULED'  # Set to SCHEDULED trigger type
      Schedule: 'cron(0 16 * * ? *)'  # Runs every day at 12:00 PM EDT (4:00 PM UTC)
      WorkflowName: !Ref GlueWorkflow
      Actions:
        - JobName: !Ref GlueDynamoDBtoS3Job
      StartOnCreation: true

  # Glue Table creation with schema for querying in Athena
  GlueTable:
    Type: AWS::Glue::Table
    Properties:
      DatabaseName: 'customerdb'
      CatalogId: !Ref AWS::AccountId
      TableInput:
        Name: 'event_feedback_table'
        TableType: 'EXTERNAL_TABLE'
        StorageDescriptor:
          Columns:
            - Name: 'event_id'
              Type: 'string'
            - Name: 'event_date'
              Type: 'string'
            - Name: 'event_name'
              Type: 'string'
            - Name: 'event_rate'
              Type: 'double'
            - Name: 'why_this_rate'
              Type: 'string'
            - Name: 'presentation_content'
              Type: 'double'
            - Name: 'session_duration'
              Type: 'double'
          Location: 's3://aws-customer-survey-analytics/events_parquet/'
          InputFormat: 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'
          OutputFormat: 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
          SerdeInfo:
            SerializationLibrary: 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
        Parameters:
          classification: 'parquet'
          compressionType: 'none'
    DependsOn: S3BucketForParquet

Outputs:
  GlueJobName:
    Description: "Name of the Glue Job"
    Value: !Ref GlueDynamoDBtoS3Job

  GlueTableName:
    Description: "Name of the Glue Table"
    Value: !Ref GlueTable

  S3BucketName:
    Description: "Name of the S3 Bucket"
    Value: !Ref S3BucketForParquet
